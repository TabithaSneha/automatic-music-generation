{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66f57418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading various libraries\n",
    "from music21 import *\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import LSTM,Dense,Input,Dropout\n",
    "from tensorflow.keras.models import Sequential,Model,load_model \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "885f7bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "def read_files(file):\n",
    "  notes=[]\n",
    "  notes_to_parse=None\n",
    "  # Parsing the midi file\n",
    "  midi_file=converter.parse(file)\n",
    "  # Seperating all the instruments from the file\n",
    "  instr=instrument.partitionByInstrument(midi_file)\n",
    "\n",
    "  for part in instr.parts:\n",
    "    # Obtaining data only of Piano instrument\n",
    "    if 'Piano' in str(part):\n",
    "      notes_to_parse=part.recurse()\n",
    "\n",
    "      # Iterating over all the parts of sub stream elements to check if element's type is Note or Chord. If it is Chord, split them into notes.\n",
    "      for element in notes_to_parse:\n",
    "        if type(element)==note.Note:\n",
    "          notes.append(str(element.pitch))\n",
    "        elif type(element)==chord.Chord:\n",
    "          notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "  # Returning all the notes in one file\n",
    "  return notes\n",
    "\n",
    "# Calling files recursively from the directory\n",
    "file_path=[\"mozart\"]\n",
    "all_files=glob.glob(\"D:/TABITHA/InnoRave/automatic-music-generation-codes/\" + 'All Midi Files/'+file_path[0]+'/*.mid',recursive=True)\n",
    "\n",
    "# Collecting all the notes from each midi file in directory\n",
    "notes_array = np.array([read_files(i) for i in tqdm(all_files,position=0,leave=True)], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b79c3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Notes: 147\n",
      "\n",
      "Frequency : No of Notes\n",
      "30 : 50\n",
      "50 : 32\n",
      "70 : 27\n",
      "90 : 25\n"
     ]
    }
   ],
   "source": [
    "# Unique Notes\n",
    "notes1 = sum(notes_array,[]) \n",
    "unique_notes = list(set(notes1))\n",
    "print(\"Unique Notes:\",len(unique_notes))\n",
    "\n",
    "# Mapping Notes with their Frequency\n",
    "freq=dict(map(lambda x: (x,notes1.count(x)),unique_notes))\n",
    "\n",
    "print(\"\\nFrequency : No of Notes\")\n",
    "for i in range(30,100,20):\n",
    "  print(i,\":\",len(list(filter(lambda x:x[1]>=i,freq.items()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "634bdb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering notes greater than threshold frequency=50 Hz\n",
    "freq_notes=dict(filter(lambda x:x[1]>=50,freq.items()))\n",
    "\n",
    "# Creating new notes using the frequent notes\n",
    "new_notes=[[i for i in j if i in freq_notes] for j in notes_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b9686e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary having 'note index:note'\n",
    "ind_note=dict(enumerate(freq_notes))\n",
    "\n",
    "# Dictionary having 'note:note index'\n",
    "note_ind=dict(map(reversed,ind_note.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccad905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps=50\n",
    "\n",
    "# Storing values of input(x) and output(y)\n",
    "x=[] ; y=[]\n",
    "\n",
    "for i in new_notes:\n",
    "  for j in range(0,len(i)-timesteps):\n",
    "    # Input will be the current index + timestep. Output will be the next index after timestep.\n",
    "    inp=i[j:j+timesteps] \n",
    "    out=i[j+timesteps]\n",
    "\n",
    "    # Appending the index value of respective notes \n",
    "    x.append(list(map(lambda x:note_ind[x],inp)))\n",
    "    y.append(note_ind[out])\n",
    "\n",
    "x_new=np.array(x) \n",
    "y_new=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea291b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping input and output for the model\n",
    "x_new = np.reshape(x_new,(len(x_new),timesteps,1))\n",
    "y_new = np.reshape(y_new,(-1,1))\n",
    "\n",
    "# Spliting the input into 80% for training and 20% for testing sets\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_new,y_new,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "030e0b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50, 256)           264192    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50, 256)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 863,520\n",
      "Trainable params: 863,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating the model with two stacked LSTM layers with the latent dimension of 256\n",
    "model = Sequential()\n",
    "model.add(LSTM(256,return_sequences=True,input_shape=(x_new.shape[1],x_new.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "\n",
    "# Fully connected layer for the output with softmax activation\n",
    "model.add(Dense(len(note_ind),activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fad481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model using Adam optimizer\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Training the model on training sets and validating on testing sets\n",
    "output = model.fit(x_train,y_train,\n",
    "                   batch_size=512,epochs=120, \n",
    "                   validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80f494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save(\"trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model=load_model(\"trained\")\n",
    "\n",
    "# Generate random index\n",
    "index = np.random.randint(0,len(x_test)-1)\n",
    "\n",
    "# Get the data of generated index from x_test\n",
    "music_pattern = x_test[index]\n",
    "\n",
    "# For storing the predicted notes\n",
    "out_pred_notes=[]\n",
    "\n",
    "# Iterate till 200 notes are generated\n",
    "for i in range(200):\n",
    "  # Reshape the music pattern \n",
    "  music_pattern = music_pattern.reshape(1,len(music_pattern),1)\n",
    "  \n",
    "  # Get the maximum probability value from the predicted output\n",
    "  pred_index = np.argmax(model.predict(music_pattern))\n",
    "\n",
    "  # Get the note using predicted index and append to the output prediction list\n",
    "  out_pred_notes.append(ind_note[pred_index])\n",
    "  music_pattern = np.append(music_pattern,pred_index)\n",
    "  \n",
    "  # Update the music pattern with one timestep ahead\n",
    "  music_pattern = music_pattern[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51cdc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notes = []\n",
    "for offset,pattern in enumerate(out_pred_notes):\n",
    "  # If pattern is a chord instance, split notes from the chord\n",
    "  if ('.' in pattern) or pattern.isdigit():\n",
    "    notes_in_chord = pattern.split('.')\n",
    "    notes = []\n",
    "    for current_note in notes_in_chord:\n",
    "        i_curr_note=int(current_note)\n",
    "        # Cast the current note to Note object and append the current note \n",
    "        new_note = note.Note(i_curr_note)\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        notes.append(new_note)\n",
    "    \n",
    "    #cast the current note to Chord object. Offset will be 1 step ahead from the previous note as it will prevent notes to stack up \n",
    "    new_chord = chord.Chord(notes)\n",
    "    new_chord.offset = offset\n",
    "    output_notes.append(new_chord)\n",
    "  \n",
    "  else:\n",
    "    # Cast the pattern to Note object, apply the offset and append the note\n",
    "    new_note = note.Note(pattern)\n",
    "    new_note.offset = offset\n",
    "    new_note.storedInstrument = instrument.Piano()\n",
    "    output_notes.append(new_note)\n",
    "\n",
    "# Save the midi file \n",
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp='Mozart-512,120.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4f9177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the graph of \"Accuracy\"\n",
    "plt.plot(output.history['accuracy'])\n",
    "plt.plot(output.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa7f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the graph of \"Loss\"\n",
    "plt.plot(output.history['loss'])\n",
    "plt.plot(output.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
